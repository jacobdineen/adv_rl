{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# pylint: disable-all\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.classifiers import DQNDNN\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def get_cnn_model(input_shape) -> nn.Sequential:\n",
    "    channel_count = input_shape[0]\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(channel_count, 64, kernel_size=(5, 5), padding=\"same\").to(device),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Conv2d(64, 64, kernel_size=(5, 5), padding=\"same\").to(device),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * input_shape[1] * input_shape[2], 128).to(device),\n",
    "        nn.ReLU(),\n",
    "    ).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dnn_model(number_of_class_labels) -> nn.Sequential:\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(number_of_class_labels, 128).to(device), nn.ReLU()\n",
    "    ).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "class QModel(nn.Module):\n",
    "    def __init__(self, cnn_model, dnn_model, blocks):\n",
    "        super().__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.dnn_model = dnn_model\n",
    "        self.blocks = blocks\n",
    "\n",
    "    def forward(self, image_input, probability_input):\n",
    "        image_representation = self.cnn_model(image_input)\n",
    "        probability_representation = self.dnn_model(probability_input)\n",
    "        x = torch.cat((probability_representation, image_representation), dim=-1)\n",
    "        x = nn.Linear(256, len(self.blocks)).to(device)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def update_q_model(experience_replay: list, q_model: QModel, batch_size: int, discount_factor: float, learning_rate=0.001):\n",
    "    q_model.train()\n",
    "    q_model_optimizer = torch.optim.Adam(q_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_input_1 = []\n",
    "    train_input_2 = []\n",
    "    train_label = []\n",
    "    for experience in shuffle(experience_replay, random_state=0)[:batch_size]:\n",
    "        experience: tuple[torch.Tensor, torch.Tensor, int, float, torch.Tensor, torch.Tensor]\n",
    "\n",
    "        (\n",
    "            sample_image,\n",
    "            sample_image_probability,\n",
    "            action_taken,\n",
    "            reward_obtained,\n",
    "            sample_image_noise,\n",
    "            sample_image_noise_probability,\n",
    "        ) = experience\n",
    "\n",
    "        # Move tensors to the device\n",
    "        initial_image_state = sample_image.to(device)\n",
    "        initial_image_probability_state = sample_image_probability.to(device)\n",
    "        next_image_state = sample_image_noise.to(device)\n",
    "        next_image_probability_state = sample_image_noise_probability.to(device)\n",
    "\n",
    "        target = q_model(\n",
    "            initial_image_state.unsqueeze(0), initial_image_probability_state\n",
    "        )[0]\n",
    "        # input(target.shape)\n",
    "\n",
    "        Q_sa = torch.max(\n",
    "            q_model(next_image_state.unsqueeze(0), next_image_probability_state)\n",
    "        )\n",
    "        # input(Q_sa.shape)\n",
    "\n",
    "        if reward_obtained == 10 or reward_obtained == -1:\n",
    "            target[action_taken] = reward_obtained\n",
    "        else:\n",
    "            target[action_taken] = reward_obtained + discount_factor * Q_sa\n",
    "\n",
    "        train_input_1.append(initial_image_state)\n",
    "        train_input_2.append(initial_image_probability_state)\n",
    "\n",
    "        train_label.append(target)\n",
    "\n",
    "    train_input_1 = torch.squeeze(torch.stack(train_input_1))\n",
    "    train_input_2 = torch.squeeze(torch.stack(train_input_2))\n",
    "    # print(train_input_1.shape)\n",
    "    # print(train_input_2.shape)\n",
    "    # input()\n",
    "\n",
    "    train_label = torch.squeeze(torch.stack(train_label))\n",
    "    # print(train_label.shape)\n",
    "    # input()\n",
    "\n",
    "    if len(train_input_1.shape) == 3:\n",
    "        train_input_1 = train_input_1.unsqueeze(-1)\n",
    "        # print(train_input_1.shape)\n",
    "        # input()\n",
    "\n",
    "    train_input_1, train_input_2, train_label = sklearn.utils.shuffle(\n",
    "        train_input_1, train_input_2, train_label, random_state=0\n",
    "    )\n",
    "\n",
    "    # print(f\"Q Model Update\")\n",
    "    q_model.train()\n",
    "\n",
    "    # Train on batch\n",
    "    t1_batch = train_input_1[0:batch_size].squeeze(-1).unsqueeze(1)\n",
    "    t2_batch = train_input_2[0:batch_size]\n",
    "    label_batch = train_label[0:batch_size]\n",
    "\n",
    "    # print(t1_batch.shape)\n",
    "    # print(t2_batch.shape)\n",
    "    # print(label_batch.shape)\n",
    "    # input()\n",
    "\n",
    "    q_model_optimizer = torch.optim.Adam(q_model.parameters(), lr=learning_rate)\n",
    "    q_model_optimizer.zero_grad()\n",
    "\n",
    "    prediction = q_model(t1_batch, t2_batch)\n",
    "    # print(prediction.shape)\n",
    "    # print(label_batch.shape)\n",
    "    # input()\n",
    "\n",
    "    loss = nn.MSELoss()(prediction, label_batch)\n",
    "    loss.backward()\n",
    "    q_model_optimizer.step()\n",
    "\n",
    "    return q_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mnist_model = DQNDNN()\n",
    "    # Load the state dictionary from the file\n",
    "    checkpoint = torch.load(\"src/model_weights/simple_mnist2.pth\", map_location=device)\n",
    "\n",
    "    # Check if the loaded state dict is a dict and has the key 'state_dict'\n",
    "    if isinstance(checkpoint, dict) and \"state_dict\" in checkpoint:\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    # Apply the state dictionary to the model\n",
    "    mnist_model.load_state_dict(state_dict)\n",
    "    mnist_model.to(device)\n",
    "    mnist_model.eval()\n",
    "\n",
    "    mnist = MNIST(\"data\", download=True, train=True)\n",
    "    dataset = mnist.data\n",
    "    labels = mnist.targets\n",
    "\n",
    "    # Deterministically splitting for now\n",
    "    (X_train, y_train) = (dataset[:50000], labels[:50000])\n",
    "    (X_test, y_test) = (dataset[50000:], labels[50000:])\n",
    "\n",
    "    input_shape = (1, 28, 28)\n",
    "    class_label_count = 10\n",
    "\n",
    "    block_size = 8\n",
    "    x_span = list(range(0, input_shape[1], block_size))\n",
    "    blocks = list(itertools.product(x_span, x_span))\n",
    "\n",
    "    cnn_model = get_cnn_model(input_shape=input_shape)\n",
    "    dnn_model = get_dnn_model(number_of_class_labels=class_label_count)\n",
    "\n",
    "    # input(torchsummary.summary(cnn_model, input_shape))\n",
    "    # input(torchsummary.summary(dnn_model, (class_label_count,)))\n",
    "\n",
    "    image_input = torch.zeros((1, *input_shape)).to(device)\n",
    "    probability_input = torch.zeros((1, class_label_count)).to(device)\n",
    "\n",
    "    # input(probability_input.shape)\n",
    "    # input(image_input.shape)\n",
    "\n",
    "    image_representation = cnn_model(image_input)\n",
    "    probability_representation = dnn_model(probability_input)\n",
    "\n",
    "    # input(image_representation.shape)\n",
    "    # input(probability_representation.shape)\n",
    "\n",
    "    x = torch.cat((probability_representation, image_representation), dim=-1).to(device)\n",
    "\n",
    "    # input(x.shape)\n",
    "\n",
    "    x = nn.Linear(256, len(blocks)).to(device)(x)\n",
    "\n",
    "    # input(x.shape)\n",
    "\n",
    "    q_model = QModel(cnn_model, dnn_model, blocks).to(device)\n",
    "    print(q_model)\n",
    "\n",
    "    # Epsilon for epsilon greedy strategy\n",
    "    epsilon = 0.9\n",
    "    batch_size = 64\n",
    "    discount_factor = 0.9\n",
    "    max_buffer_size = 2000\n",
    "    max_blocks_attack = 100\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # (1 - LAMBDA) is how much we are discounting the change in pixel value\n",
    "    LAMBDA = 1.0\n",
    "\n",
    "    success = []\n",
    "    success_rate = []\n",
    "    experience_replay = []\n",
    "\n",
    "    GAME_COUNT = 5000 * 5\n",
    "\n",
    "    # Decay epsilon every time this many games are played\n",
    "    epsilon_decay_game_count = GAME_COUNT // 10\n",
    "    # How much to decay epsilon by\n",
    "    epsilon_decay = 0.1\n",
    "    # Minimum value of epsilon\n",
    "    epsilon_minimum = 0.1\n",
    "\n",
    "    for game_number in tqdm(range(GAME_COUNT)):\n",
    "        sample_image = X_train[game_number].to(device)\n",
    "        sample_image = sample_image.unsqueeze(0)\n",
    "\n",
    "        sample_image = sample_image.float()\n",
    "\n",
    "        if game_number > 0 and game_number % epsilon_decay_game_count == 0:\n",
    "            epsilon -= epsilon_decay\n",
    "            if epsilon <= epsilon_minimum:\n",
    "                epsilon = epsilon_minimum\n",
    "            tqdm.write(f\"Decayed epsilon to {epsilon}\")\n",
    "\n",
    "        predicted_label_distribution = mnist_model(sample_image.unsqueeze(0))\n",
    "        original_predicted_label = torch.argmax(predicted_label_distribution, dim=1)\n",
    "\n",
    "        for iteration_number in range(0, max_blocks_attack):\n",
    "            sample_image_probability = mnist_model(sample_image.unsqueeze(0))[0]\n",
    "            sample_image_probability = sample_image_probability.unsqueeze(0)\n",
    "\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.randint(0, len(blocks))\n",
    "            else:\n",
    "                action = torch.argmax(\n",
    "                    q_model(sample_image.unsqueeze(0), sample_image_probability)\n",
    "                ).item()\n",
    "\n",
    "            attack_region = torch.zeros(input_shape)\n",
    "            attack_coord = blocks[action]\n",
    "            attack_region[\n",
    "                0,\n",
    "                attack_coord[0] : attack_coord[0] + block_size,\n",
    "                attack_coord[1] : attack_coord[1] + block_size,\n",
    "            ] = 1\n",
    "\n",
    "            sample_image_with_noise = sample_image + (attack_region * LAMBDA).to(device)\n",
    "            sample_image_noise_probability = mnist_model(\n",
    "                sample_image_with_noise.unsqueeze(0)\n",
    "            )\n",
    "\n",
    "            modified_predicted_label = torch.argmax(\n",
    "                mnist_model(sample_image_with_noise.unsqueeze(0)), dim=1\n",
    "            )\n",
    "\n",
    "            if modified_predicted_label != original_predicted_label:\n",
    "                tqdm.write(\"Successfully tricked the classifier\")\n",
    "                reward = 20.0\n",
    "                success.append(1)\n",
    "                experience = (\n",
    "                    sample_image,\n",
    "                    sample_image_probability,\n",
    "                    action,\n",
    "                    reward,\n",
    "                    sample_image_with_noise,\n",
    "                    sample_image_noise_probability,\n",
    "                )\n",
    "                experience_replay.append(experience)\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                reward = -0.1\n",
    "                experience = (\n",
    "                    sample_image,\n",
    "                    sample_image_probability,\n",
    "                    action,\n",
    "                    reward,\n",
    "                    sample_image_with_noise,\n",
    "                    sample_image_noise_probability,\n",
    "                )\n",
    "                experience_replay.append(experience)\n",
    "\n",
    "            sample_image = sample_image_with_noise\n",
    "            # input(sample_image.shape)\n",
    "\n",
    "        if iteration_number == max_blocks_attack - 1:\n",
    "            # print(\"Failure\")\n",
    "\n",
    "            reward = -10.0\n",
    "            success.append(0)\n",
    "            experience = (\n",
    "                sample_image,\n",
    "                sample_image_probability,\n",
    "                action,\n",
    "                reward,\n",
    "                sample_image_with_noise,\n",
    "                sample_image_noise_probability,\n",
    "            )\n",
    "            experience_replay.append(experience)\n",
    "\n",
    "        if len(experience_replay) > max_buffer_size:\n",
    "            tqdm.write(f\"Updating Q Model\")\n",
    "            q_model = update_q_model(\n",
    "                experience_replay, q_model, batch_size, discount_factor, learning_rate\n",
    "            )\n",
    "            experience_replay = []\n",
    "\n",
    "            tqdm.write(f\"Successes: {success}\")\n",
    "            tqdm.write(f\"Updated Q Model: Episode success rate {np.mean(np.array(success)) * 100}%\")\n",
    "            success_rate.append(np.mean(np.array(success)))\n",
    "            success = []\n",
    "\n",
    "        if game_number % 100 == 0:\n",
    "            tqdm.write(\n",
    "                f\"Episode: {game_number}\"\n",
    "            )\n",
    "\n",
    "    print(f\"Final success: {np.mean(np.array(success))}\")\n",
    "    print(f\"Overall success rate: {success_rate}\")\n",
    "    print(f\"Saving model to q_model.pt\")\n",
    "    torch.save(q_model.state_dict(), \"q_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
